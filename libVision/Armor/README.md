# 装甲板识别类
## 识别流程
### 双目

![](https://s3.bmp.ovh/imgs/2021/08/09e89be69600562d.png)

1. 读取相机个数
    判断读入了几个图像
2. 多线程运行单目识别
    根据图像数目决定是单目还是双目
3. 根据识别结果判断是继续双目识别还是切换为单目识别
    如果左右相机识别都有结果，就进行双目；
    如果只有一个相机有结果，就进行单目识别
4. 双目匹配和初始化（为下一帧识别做准备）
    给单目识别类赋值上一帧装甲板信息，识别状态等
5. 测距
    单目测距或双目测距
6. 返回结果
### 单目

![](https://s3.bmp.ovh/imgs/2021/08/1aad18163837dfcf.png)

1. 图像预处理
    进行分通道、二值化、ROI选择、开闭操作等得到二值图
2. 识别灯条
    用找二值图轮廓的方法找灯条，然后用几何条件、颜色条件等筛选，尽可能找到符合条件的灯条
3. 识别装甲板
    灯条两两匹配，找到所有装甲板，根据几何条件筛选
4. 找目标装甲板
    用数字识别，形态学匹配等方法找目标装甲板
5. 返回结果

## 识别原理分析

装甲板识别使用的是传统识别，利用装甲板灯条发光，通过一系列图像处理得到二值图像。

![](https://s3.bmp.ovh/imgs/2021/08/a2fb170947c9baa0.png)

然后利用找轮廓的函数找出所有轮廓，通过各种几何条件判断以及颜色判断，找到正确的装甲板灯条。

![](https://s3.bmp.ovh/imgs/2021/08/b4558b836508d559.png)

灯条两两匹配，找到初始装甲板。

![](https://s3.bmp.ovh/imgs/2021/08/1618ae479cefa74c.png)

初始装甲板经过几何条件的筛选和一些极端条件的滤除，得到符合条件的装甲板，这里得到的装甲板符合装甲板的基本特征，但为了准确度还要进行数字识别来进一步筛选。

![](https://s3.bmp.ovh/imgs/2021/08/902d45272a8607ac.png)

通过计算得到数字识别的区域，然后对该区域进行数字识别。数字识别使用机器学习，用支持向量机进行分类，特岛装甲板ID。

`数字识别区域`

![](https://s3.bmp.ovh/imgs/2021/08/052f054024fbdde1.png)

`传入数字识别模型的图片`

![](https://s3.bmp.ovh/imgs/2021/08/1ba04b1b9da34563.png)

得到装甲板ID后，筛掉没有数字的和工程ID，得到目标装甲板。

![](https://s3.bmp.ovh/imgs/2021/08/c7ecaf36898d7d24.png)

### 双目识别原理

双目识别主要是因为使用双目测距，但双目识别也可以滤除掉一部分的误识别，并且在单目精度足够时有更大的视野范围。

双目识别部分主要是在左右目相机分别完成单目识别后，对单目识别结果进行处理。主要包括赋值ROI、双目匹配、单双目切换、深度筛选等。

双目匹配的原理就是根据几何条件（长度比、宽度比、角度差等）以及装甲板ID判断左右目识别到的是不是同一块装甲板，然后根据视差是否在一个合理范围内，避免过远或视差过大（不是同一装甲板）的目标。

![](https://s3.bmp.ovh/imgs/2021/08/7f194460557474bb.png)

这里其实对一部分误识别有一定的滤除效果，因为只有两个相机都识别到才会返回识别成功，但同时也增大了丢识别的风险。

### 双目的优点

#### 单目和双目视野对比

![](https://s3.bmp.ovh/imgs/2021/08/e6ac80a04b1fd5f5.jpg)

#### 分析

双目的优势在于，双目测距的精度很高。单目测距在使用传统识别时，装甲板角点时根据灯条选择的，所以不可避免的会收到环境光线的影响，导致测距出现偏差，所以很难在远距离达到较高的测距精度。而双目测距只需要找一个点，就可以得到该点的深度信息，可以比较容易的达到更高的精度。

同时，双目测距理论上拥有更大的视野范围，在有单双目切换的时候，近战可以更好的捕捉到视野边缘的装甲板。同时由于双目区域在中间，同时双目测距相较于单目测距精度更高，在视野中间远距离吊射的时候，测距也更加精准。

## 调试 

调试识别测试文件为 `DoubleArmorTest.cpp`
运行测试文件需要给出识别状态，否则默认为双目识别
0 对应 单目debug状态
1 对应 单目状态
2 对应 双目状态
3 对应 双目debug状态

## 未来发展

这一套识别系统最大的问题是太依赖场地调试了，如果没有合适的曝光和阈值，识别很容易出现问题。曝光不合适时就算识别勉强能用，由于机器学习只能简单分类数字，也会有很多误识别。而且在灯条周围亮度较高时，会出现灯条和周围环境混在一起，没有正确二值画，导致比较严重的丢帧。

所以未来的发展方向有两个方面，一是寻求传统视觉自动曝光的方法，或者有效的滤除杂光的方法，来提升这套识别系统的稳定性。二是使用深度学习直接识别。要尽可能提升识别的场地适应能力，做到“开箱即用“。

同时要加入滤波层，在结果传入控制系统前对丢帧和误识别进行一定的滤波，保证识别结果的准确性。
